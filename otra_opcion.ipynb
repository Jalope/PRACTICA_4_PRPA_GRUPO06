{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f15b3ee5-3204-44ab-914d-22360677916b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at /tmp/ipykernel_6153/414631668.py:2 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6153/414631668.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \" is not allowed as it is a security risk.\")\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                     \u001b[0;31m# Raise error if there is already a running Spark context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m    351\u001b[0m                         \u001b[0;34m\"Cannot run multiple SparkContexts at once; \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                         \u001b[0;34m\"existing SparkContext(app=%s, master=%s)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at /tmp/ipykernel_6153/414631668.py:2 "
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83813b21-3d27-4c5e-9603-d30422476ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -1 201704_Usage_Bicimad.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89f2fd56-3686-4f30-aac4-966ca8c02c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d405c532-4de7-49eb-b89b-1d372e9bdb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper(line):\n",
    "    data = json.loads(line)\n",
    "    usert = data['user_type']\n",
    "    time = data['travel_time']\n",
    "    date = convert_date(data['unplug_hourTime'])\n",
    "    return usert, time, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55436c9f-0d34-48ce-bb07-6912f2a13feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date(date):\n",
    "    if isinstance(date, str):\n",
    "        date = date.replace(\"Z\",\"+0000\")\n",
    "        date = datetime.datetime.strptime(date, \"%Y-%m-%dT%H:%M:%S%z\")\n",
    "    else:\n",
    "        date = date['$date']\n",
    "        date = datetime.datetime.strptime(date, \"%Y-%m-%dT%H:%M:%S.%f%z\")\n",
    "    return (date.month,date.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "932ff24c-b38b-49a2-aab2-18750ce768a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 12)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_date({ \"$date\" : \"2019-06-01T12:40:00.000+0200\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d240cbdc-2d7e-4e4a-a3de-ca1edfcca7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_base = sc.textFile('sample01.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ac00133-c4df-4de2-80a2-b8ea6ff0aff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = rdd_base.map(mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39286ed8-41a7-4044-a40d-4edbd00b8a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {1: 1707, 3: 130, 0: 206, 2: 7})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.countByKey()\n",
    "#0: no ha sido posible determinarlo, 1: pase anual, 2: ocasional, 3: empresa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3d095cd-6ba9-4ee1-9f63-6ec867536d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1707\n",
      "7\n",
      "130\n"
     ]
    }
   ],
   "source": [
    "rdd_user1 = rdd.filter(lambda x: x[0]==1).map(lambda x: (x[2][0],x[1],x[2][1]))#mes, tiempo(s), hora(24)\n",
    "n1 = rdd_user1.count()\n",
    "print(n1)\n",
    "rdd_user2 = rdd.filter(lambda x: x[0]==2).map(lambda x: (x[2][0],x[2][1],x[1]))#mes, hora 24h, tiempo seg.\n",
    "n2 = rdd_user2.count()\n",
    "print(n2)\n",
    "rdd_user3 = rdd.filter(lambda x: x[0]==3).map(lambda x: (x[2][0],x[1],x[2][1]))\n",
    "n3 = rdd_user3.count()\n",
    "print(n3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f588e44e-c0e7-4816-992f-1f6319c1d88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 17, 2409),\n",
       " (10, 10, 392),\n",
       " (10, 11, 9236),\n",
       " (10, 12, 890),\n",
       " (10, 11, 735),\n",
       " (10, 17, 2036),\n",
       " (10, 10, 3239)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_user2.take(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c917b1-3e5a-454a-9a7b-8c77d0c598e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
